import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from collections import defaultdict
from sklearn.utils import shuffle
import joblib

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
SEQ_LENGTH = 5
N_ESTIMATORS = 150
MAX_DEPTH = 20
DATA_PATH = 'LearningDataForLSTMFar.txt'
TEST_SPLIT = 0.2
VARIANTS = ["classic", "global_shuffle", "by_distance_shuffle", "stride_window", "random_chunks"]
RANDOM_SEED = 42

# === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
df = pd.read_csv(DATA_PATH, header=None, names=["distance", "rssi"])

def create_dataset(df, method="classic"):
    X, y = [], []
    if method == "classic":
        for dist in df['distance'].unique():
            rssi_values = df[df['distance'] == dist]['rssi'].values
            for i in range(SEQ_LENGTH, len(rssi_values)):
                X.append(rssi_values[i - SEQ_LENGTH:i])
                y.append(dist)

    elif method == "global_shuffle":
        df_shuffled = shuffle(df, random_state=RANDOM_SEED)
        rssi_values = df_shuffled['rssi'].values
        distances = df_shuffled['distance'].values
        for i in range(SEQ_LENGTH, len(rssi_values)):
            X.append(rssi_values[i - SEQ_LENGTH:i])
            y.append(distances[i])

    elif method == "by_distance_shuffle":
        for dist in df['distance'].unique():
            group = df[df['distance'] == dist]
            group = shuffle(group, random_state=RANDOM_SEED)
            rssi_values = group['rssi'].values
            for i in range(SEQ_LENGTH, len(rssi_values)):
                X.append(rssi_values[i - SEQ_LENGTH:i])
                y.append(dist)

    elif method == "stride_window":
        for dist in df['distance'].unique():
            rssi_values = df[df['distance'] == dist]['rssi'].values
            for i in range(0, len(rssi_values) - SEQ_LENGTH, 2):  # —à–∞–≥ 2
                X.append(rssi_values[i:i + SEQ_LENGTH])
                y.append(dist)

    elif method == "random_chunks":
        all_rssi = df['rssi'].values
        all_dist = df['distance'].values
        for _ in range(4000):  # –æ–≥—Ä–∞–Ω–∏—á–∏–º —á–∏—Å–ª–æ –æ–∫–æ–Ω
            start = np.random.randint(0, len(all_rssi) - SEQ_LENGTH)
            X.append(all_rssi[start:start + SEQ_LENGTH])
            y.append(all_dist[start + SEQ_LENGTH - 1])

    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è: {method}")

    return np.array(X), np.array(y)


# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–æ –º–µ—Ç–æ–¥–∞–º ===
results = []
for variant in VARIANTS:
    print(f"\nüß™ –í–∞—Ä–∏–∞–Ω—Ç: {variant}")
    X, y = create_dataset(df, method=variant)

    # –î–µ–ª–∏–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç
    split_index = int(len(X) * (1 - TEST_SPLIT))
    X_train, X_test = X[:split_index], X[split_index:]
    y_train, y_test = y[:split_index], y[split_index:]

    # –û–±—É—á–µ–Ω–∏–µ
    model = RandomForestRegressor(n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH, random_state=RANDOM_SEED)
    model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    y_pred = model.predict(X_test)

    # MAE –æ–±—â–∏–π
    overall_mae = mean_absolute_error(y_test, y_pred)

    # MAE –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º
    mae_by_distance = defaultdict(list)
    for true, pred in zip(y_test, y_pred):
        mae_by_distance[true].append(abs(true - pred))

    print(f"üìä –û–±—â–∏–π MAE: {overall_mae:.4f} –º")
    results.append((variant, overall_mae))


# === –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
print("\nüìã –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –≤–∞—Ä–∏–∞–Ω—Ç–∞–º:")
for variant, mae in results:
    print(f"{variant:20s} ‚Üí MAE = {mae:.4f} –º")
